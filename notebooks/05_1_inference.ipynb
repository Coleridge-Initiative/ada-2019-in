{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Education and Multistate Employment Data\n",
    "\n",
    "### Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setting up a Database Connection](#Database-Connection)\n",
    "3. [Education Queries ](#Writing-Our-Education-Database-Query)\n",
    "4. [Identifying People in Multiple Datasets](#Linking-Ohio-Education-and-Employment-Microdata)\n",
    "5. [Explore the Connected Data](#Exploratory-Data-Analysis)\n",
    "6. [Identifying People Across Multiple States](#Linking-Ohio-Education-and-Multistate-Employment-Microdata)\n",
    "7. [Additional Data Exploration:Multistate Wages](#Additional-Exploratory-Data-Analysis)\n",
    "8. [Exploring Sources of Errors and Inference](#Exploring-Sources-of-Error-and-Inference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this notebook, we use Ohio administrative data on earned education degrees. We will identify a specific type of education program and select a specific cohort (a group of students who graduated in the same year). \n",
    "\n",
    "Next, we see if we can find employment outcomes for this group of students. Here, we have to think of the type of employment outcome we are interested in. How many years after graduation and when do we identify someone as being employed? \n",
    "\n",
    "In addition, we have to think about where to find these employment outcomes. We can investigate the Ohio administrative data on employment, but we can also investigate if students became employed in some other states. \n",
    "\n",
    "By going through this notebook, you get an idea of all the choices you make while going through such a process, and you get an idea of how these decisions influences the outcomes you will find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the packages we are going to use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "First we set our database connection parameters\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_name = \"appliedda\"\n",
    "hostname = \"10.10.2.10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set our database connections, and we use the psycopg2 module so we can more easily execute queries without returning data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=db_name, host=hostname)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Our Education Database Query \n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Note that with this query, we identify and select only persons who obtained a education degree with 'cip' = '23', which equates to a bachelor's degree in English. In addition, we only include persons who obtained their degree in 2010. When you are finished with going through this notebook, you can come back to this query and play around with selecting other degrees or other cohorts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use list comprehension to shorten the list of table names in our query text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_list = ['degcert_au_inst1_level_{}'.format(i) for i in range(1, 17)] +\\\n",
    "['degcert_sm_inst1_level_{}'.format(i) for i in range(1, 12)] +\\\n",
    "['degcert_sp_inst1_level_{}'.format(i) for i in range(1, 18)] +\\\n",
    "['degcert_wi_inst1_level_{}'.format(i) for i in range(1, 11)]\n",
    "level_cols = ','.join([l+'::text' for l in level_list])\n",
    "\n",
    "subject_list = ['degcert_au_inst1_subject_{}'.format(i) for i in range(1, 17)] +\\\n",
    "['degcert_sm_inst1_subject_{}'.format(i) for i in range(1, 12)] +\\\n",
    "['degcert_sp_inst1_subject_{}'.format(i) for i in range(1, 18)] +\\\n",
    "['degcert_wi_inst1_subject_{}'.format(i) for i in range(1, 11)]\n",
    "subject_cols = ','.join([s+'::text' for s in subject_list])\n",
    "\n",
    "term_list = ['degcert_au_inst1_term_earned_{}'.format(i) for i in range(1, 17)] +\\\n",
    "['degcert_sm_inst1_term_earned_{}'.format(i) for i in range(1, 12)] +\\\n",
    "['degcert_sp_inst1_term_earned_{}'.format(i) for i in range(1, 18)] +\\\n",
    "['degcert_wi_inst1_term_earned_{}'.format(i) for i in range(1, 11)]\n",
    "term_cols = ','.join([t+'::text' for t in term_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identify:\n",
    "# - (From Ohio state public institutions)\n",
    "# - English (CIP 23)\n",
    "# - Both 1st and 2nd bachelors\n",
    "# - Multiple simultaneous English language diplomas not included \n",
    "# - This is only cohort that obtained diploma in 2010\n",
    "\n",
    "SQL_EDU = '''\n",
    "CREATE TEMP TABLE cohort_2010 AS\n",
    "SELECT DISTINCT ON (key_id) key_id, format('%s-%s-1', deg_year, deg_term::int*3-2)::date yr_q\n",
    "FROM (SELECT key_id, file_year AS \"deg_year\",\n",
    "    UNNEST(array[{TERM_COLS}]) AS \"deg_term\",\n",
    "    UNNEST(array[{SUBJECT_COLS}]) AS \"cip\",\n",
    "    UNNEST(array[{LEVEL_COLS}]) AS \"degr_lvl\"\n",
    "    FROM data_ohio_olda_2018.oh_hei\n",
    "    WHERE file_year = '2010'\n",
    ") q\n",
    "WHERE deg_term IS NOT NULL\n",
    "AND LEFT(cip, 2)='23'\n",
    "AND (degr_lvl ='5' OR \n",
    "      degr_lvl ='22')\n",
    "ORDER BY key_id, deg_term, deg_year;\n",
    "COMMIT;\n",
    "'''.format(TERM_COLS = term_cols, SUBJECT_COLS = subject_cols, LEVEL_COLS = level_cols)\n",
    "\n",
    "cursor.execute(SQL_EDU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just generated a SQL query to select our group of interest and stored it in a TEMP TABLE. We now load it into a panda dataframe so that we are able to investigate it in a bit more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the 2010 cohort \n",
    "SQL_LOAD_EDU = '''\n",
    "SELECT *\n",
    "FROM cohort_2010\n",
    "'''\n",
    "df_edu = pd.read_sql(SQL_LOAD_EDU, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people (or actually 'degrees') are in our cohort? And how many variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_edu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the variables mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there persons in here who obtained multiple degrees? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_edu['key_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Ohio Education and Employment Microdata\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "As you saw in the 'education dataset'  that we just generated, persons are identified with 'key_id'. As this is an Ohio specific identification method, we also find the corresponding SSN numbers. Apparently these are hashed, so we link the corresponding values for 'ssn_hash'. The 'ssn_hash' values corresponding to 'key_id' are found in ' data_ohio_olda_2018.oh_person. We save this in a TEMP TABLE so that we can use it later in other SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EDU_SSN_2 = \"\"\"\n",
    "CREATE TEMP TABLE cohort_2010_EDU_SSN AS\n",
    "SELECT a.key_id, a.yr_q, b.ssn_hash\n",
    "FROM cohort_2010 a\n",
    "LEFT JOIN data_ohio_olda_2018.oh_person b\n",
    "ON a.key_id = b.key_id;\n",
    "\n",
    "COMMIT;\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EDU_SSN_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the linking worked, we also load it into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SQL_EDU_SSN_test = \"\"\"\n",
    "SELECT a.key_id, a.yr_q, b.ssn_hash\n",
    "FROM cohort_2010 a\n",
    "LEFT JOIN data_ohio_olda_2018.oh_person b\n",
    "ON a.key_id = b.key_id;\n",
    "\"\"\"\n",
    "df_edu_ssn = pd.read_sql(SQL_EDU_SSN_test, conn)\n",
    "df_edu_ssn['ssn_hash'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified a cohort of students of interest, and linked their SSN numbers, we can start by looking for the employment outcomes for these students. \n",
    "\n",
    "We will use a very specific definition for employment here, namely 'full quarter employment one year after graduation'. Full quarter employment means that a person is employed for at least one full quarter. In order to meet this requirement, there should also an employment registration for this person at the same employed in the previous and subsequent quarter. \n",
    "\n",
    "As our cohort consists of people who graduated in quarters 1, 2, 3 and 4 in 2010, we are interested in employment registrations in quarters 1, 2, 3 and 4 in 2011, but to identify the 'full' quarters, we also need employment registrations of 2010 quarter 4 and 2012 quarter 1.\n",
    "\n",
    "We start by identifying all quarters within this period from the administrative data from Ohio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SQL_cohort_OH = '''\n",
    "CREATE TEMP TABLE cohort_OH AS\n",
    "SELECT *, \n",
    "format('%s-%s-1', year, quarter*3-2)::date job_yrq\n",
    "FROM data_ohio_olda_2018.oh_ui_wage_by_employer a\n",
    "WHERE (year = 2011 OR (year = 2010 AND quarter = 4) \n",
    "        OR (year = 2012 AND quarter = 1))\n",
    "    AND key_id IN (SELECT key_id FROM cohort_2010_EDU_SSN);\n",
    "\n",
    "COMMIT;\n",
    "'''\n",
    "cursor.execute(SQL_cohort_OH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for all the selected quarters, we identify which meet the 'full quarter' requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EMP_2_OH = \"\"\"\n",
    "CREATE TEMP TABLE cohort_OH_full AS \n",
    "SELECT a.* \n",
    "from cohort_OH a, cohort_OH b, cohort_OH c\n",
    "where a.key_id=b.key_id\n",
    "    AND a.key_id=c.key_id \n",
    "    AND a.employer = b.employer \n",
    "    AND a.employer = c.employer\n",
    "    AND a.job_yrq = (b.job_yrq - '3 month'::interval)::date\n",
    "    AND a.job_yrq = (c.job_yrq + '3 month'::interval)::date;\n",
    "    \n",
    "commit;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EMP_2_OH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this 'Ohio employment' dataset we just generated also doesn't contain SSN's, we again link them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EMP_3_OH = \"\"\"\n",
    "CREATE TEMP TABLE cohort_OH_full_SSN AS\n",
    "SELECT a.*, b.ssn_hash\n",
    "    FROM cohort_OH_full a\n",
    "LEFT JOIN data_ohio_olda_2018.oh_person b\n",
    "    ON a.key_id = b.key_id;\n",
    "\n",
    "COMMIT;\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EMP_3_OH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 'employment dataset' we generated only contains employment information from Ohio. We are going to look at other states for employment information as well, and in the final dataset we would like to have a variable identifying from which state the employment information originated (so in which state this person is actually employed). Therefore, we now generate a variable 'state' which all has the state code '39'  for the Ohio people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EMP_4_OH = \"\"\"\n",
    "ALTER TABLE cohort_OH_full_SSN\n",
    "ADD state text DEFAULT '39';\n",
    "\n",
    "commit;\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EMP_4_OH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We now investigate how the dataset we just generated looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SQL_OH = '''\n",
    "SELECT *\n",
    "FROM cohort_OH_full_SSN\n",
    "'''\n",
    "df_OH = pd.read_sql(SQL_OH, conn)\n",
    "df_OH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('the number of individual graduates represented in the Ohio dataset is'), df_OH['key_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_OH.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Ohio Education and Multistate Employment Microdata\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "So apparently this dataset contains 2938 quarters with employment information from 918 individuals. Note that at this point, we did not merge the education information to the employment information yet. So this are just all the quarters meeting our definition from the people in the cohort. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to see if we can also identify persons of this cohort in employment registrations in other states. We start by Missouri. Here, we use the SSN's of the Ohio education cohort to identify persons in the Missouri employment dataset, and we use the exact same definition of 'full quarter employment'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_cohort_MO = '''\n",
    "CREATE TEMP TABLE cohort_MO AS\n",
    "SELECT *, \n",
    "format('%s-%s-1', year, quarter*3-2)::date job_yrq\n",
    "FROM kcmo_lehd.mo_wage a\n",
    "WHERE (year = 2011 OR (year = 2010 AND quarter = 4) \n",
    "        OR (year = 2012 AND quarter = 1))\n",
    "    AND SSN IN (SELECT ssn_hash FROM cohort_2010_EDU_SSN);\n",
    "\n",
    "COMMIT;\n",
    "'''\n",
    "cursor.execute(SQL_cohort_MO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for Missouri, we identify which of the quarters meet the 'full quarter' requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_cohort_MO_full = \"\"\"\n",
    "CREATE TEMP TABLE cohort_MO_full AS \n",
    "SELECT a.* \n",
    "from cohort_MO a, cohort_MO b, cohort_MO c\n",
    "where a.ssn=b.ssn \n",
    "    AND a.ssn=c.ssn \n",
    "    AND a.empr_no = b.empr_no \n",
    "    AND a.empr_no = c.empr_no\n",
    "    AND a.job_yrq = (b.job_yrq - '3 month'::interval)::date\n",
    "    AND a.job_yrq = (c.job_yrq + '3 month'::interval)::date;\n",
    "    \n",
    "commit;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(SQL_cohort_MO_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we check how the Missouri dataset we just generated looks like. As you can see here, SSN is already in here as well as a 'state' variable, indicating this data originates from Missouri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the Missouri set\n",
    "SQL_MO = '''\n",
    "SELECT *\n",
    "FROM cohort_MO_full\n",
    "'''\n",
    "df_MO = pd.read_sql(SQL_MO, conn)\n",
    "df_MO.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the same steps on data from the state Illinois: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_cohort_IL_full = '''\n",
    "CREATE TEMP TABLE cohort_IL AS\n",
    "SELECT *, \n",
    "format('%s-%s-1', year, quarter*3-2)::date job_yrq\n",
    "FROM il_des_kcmo.il_wage a\n",
    "WHERE (year = 2011 OR (year = 2010 AND quarter = 4) \n",
    "        OR (year = 2012 AND quarter = 1))\n",
    "    AND SSN IN (SELECT ssn_hash FROM cohort_2010_EDU_SSN);\n",
    "\n",
    "COMMIT;\n",
    "'''\n",
    "cursor.execute(SQL_cohort_IL_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EMP_2_IL = \"\"\"\n",
    "CREATE TEMP TABLE cohort_IL_full AS \n",
    "SELECT a.* \n",
    "from cohort_IL a, cohort_IL b, cohort_IL c\n",
    "where a.ssn=b.ssn \n",
    "    AND a.ssn=c.ssn \n",
    "    AND a.empr_no = b.empr_no \n",
    "    AND a.empr_no = c.empr_no\n",
    "    AND a.job_yrq = (b.job_yrq - '3 month'::interval)::date\n",
    "    AND a.job_yrq = (c.job_yrq + '3 month'::interval)::date;\n",
    "    \n",
    "commit;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EMP_2_IL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SQL_IL = '''\n",
    "SELECT *\n",
    "FROM cohort_IL_full\n",
    "'''\n",
    "df_IL= pd.read_sql(SQL_IL, conn)\n",
    "df_IL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the state of Indiana..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_cohort_IN_full = '''\n",
    "CREATE TEMP TABLE cohort_IN AS\n",
    "SELECT *, \n",
    "format('%s-%s-1', year, quarter*3-2)::date job_yrq\n",
    "FROM in_data_2019.wages_by_employer a\n",
    "WHERE (year = 2011 OR (year = 2010 AND quarter = 4) \n",
    "        OR (year = 2012 AND quarter = 1))\n",
    "    AND SSN IN (SELECT ssn_hash FROM cohort_2010_EDU_SSN);\n",
    "\n",
    "COMMIT;\n",
    "'''\n",
    "cursor.execute(SQL_cohort_IN_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EMP_2_IN = \"\"\"\n",
    "CREATE TEMP TABLE cohort_IN_full AS \n",
    "SELECT a.* \n",
    "from cohort_IN a, cohort_IN b, cohort_IN c\n",
    "where a.ssn=b.ssn \n",
    "    AND a.ssn=c.ssn \n",
    "    AND a.fein = b.fein \n",
    "    AND a.fein = c.fein\n",
    "    AND a.job_yrq = (b.job_yrq - '3 month'::interval)::date\n",
    "    AND a.job_yrq = (c.job_yrq + '3 month'::interval)::date;\n",
    "    \n",
    "commit;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EMP_2_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SQL_IN = '''\n",
    "SELECT *\n",
    "FROM cohort_IN_full\n",
    "'''\n",
    "df_IN= pd.read_sql(SQL_IN, conn)\n",
    "df_IN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_EMP_4_IN = \"\"\"\n",
    "ALTER TABLE cohort_IN_full\n",
    "ADD state text DEFAULT '18';\n",
    "\n",
    "commit;\n",
    "\"\"\"\n",
    "cursor.execute(SQL_EMP_4_IN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge the employment information from the four different states. Note that we cannot just merge the four complete datasets as they are, as they all have some unique variables. We first identify the ones that are similar, which are: 'ssn', 'state', 'wage' and 'job_yrq'. Note that the variables are sometimes spelled a bit differently over different states. Also note that we are not including any information identifying multiple employers, as this information is not generalizable over different states. This is information we are losing by doing this merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_MERGE_MO_IL = \"\"\"\n",
    "CREATE TEMP TABLE cohort_merge AS\n",
    "SELECT ssn, state, wage, job_yrq FROM cohort_MO_full\n",
    "UNION ALL\n",
    "SELECT ssn, state, wage, job_yrq FROM cohort_IL_full\n",
    "UNION ALL \n",
    "SELECT ssn, state, wages, job_yrq FROM cohort_IN_full\n",
    "UNION ALL\n",
    "SELECT ssn_hash, state, wages, job_yrq FROM cohort_OH_full_SSN;\n",
    "\n",
    "commit;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(SQL_MERGE_MO_IL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exploratory Data Analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "And we investigate how the merged dataset looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SQL_OH_TEST = \"\"\"\n",
    "SELECT * FROM cohort_merge;\n",
    "\"\"\"\n",
    "df_test = pd.read_sql(SQL_OH_TEST, conn)\n",
    "df_test['ssn'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we obtained all employment information for our cohort that we were able to find in the available administrative registries, we can link this information to the education cohort dataset. We use 'LEFT JOIN' in such a way that we only link the employment information exactly one year later (same quarter) to the education cohort data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_link_edu_emp = \"\"\"\n",
    "CREATE TEMP TABLE cohort_2010_test AS\n",
    "SELECT cohort_2010_EDU_SSN.*, cohort_merge.* \n",
    "FROM cohort_2010_EDU_SSN \n",
    "LEFT JOIN cohort_merge\n",
    "ON cohort_2010_EDU_SSN.ssn_hash = cohort_merge.ssn\n",
    "    AND cohort_2010_EDU_SSN.yr_q = (cohort_merge.job_yrq -'1 year'::interval)::date;\n",
    "\n",
    "commit;\n",
    "\"\"\"\n",
    "cursor.execute(SQL_link_edu_emp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we again investigate this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_OH_TEST = \"\"\"\n",
    "SELECT * FROM cohort_2010_test;\n",
    "\"\"\"\n",
    "df_test = pd.read_sql(SQL_OH_TEST, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['key_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['ssn'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, this dataset has 1602 registrations for 1551 persons. So a couple of them had wages from multiple employers (resulting in multiple rows in this dataset). In addition, there are 686 ssns in there. SSN was only registered in the employment dataset, as we had 'key_id'  and 'ssn_hash'  in the education data. So 696 persons had employment registrations in this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw that some persons had multiple employers from whom they obtained income, there are different ways we can handle this. We can just sum all the wages for every person, or we identify the highest wage per person, and identify this as primary income. We name them 'sumwage' and 'maxwage'. Note that in the way we specified the code here, we do not sum or max wages if a person is earning wages in multiple states simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_SUM_MAX = \"\"\"\n",
    "CREATE TEMP TABLE cohort_2010_sumwages AS\n",
    "SELECT key_id, state, \n",
    "    SUM(wage) as sumwage,\n",
    "    MAX(wage) as maxwage\n",
    "FROM cohort_2010_test\n",
    "GROUP BY key_id, state;\n",
    "commit;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(SQL_SUM_MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also link a dataset with auxiliary information per person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQL_LINK_AUX = '''\n",
    "select *\n",
    "from cohort_2010_sumwages a\n",
    "left join data_ohio_olda_2018.oh_hei_demo b\n",
    "on a.key_id = b.key_id\n",
    "'''\n",
    "df_aux = pd.read_sql(SQL_LINK_AUX, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate variables measuring wages one year after employment. We generate a few different definitions here: either 'sum'  or 'max' of the wages, and we set different thresholds. A threshold here can be used to identify persons who for example earn less than the minimum wage with fulltime employment, or half of that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate wage variables with different definitions for employment\n",
    "df_aux['max_0_singleS_fullQ']    = np.where(df_aux['maxwage'] > 0, df_aux['maxwage'], np.nan)\n",
    "df_aux['sum_0_singleS_fullQ']    = np.where(df_aux['sumwage'] > 0, df_aux['sumwage'], np.nan)\n",
    "df_aux['max_1924_singleS_fullQ'] = np.where(df_aux['maxwage'] > 1924, df_aux['maxwage'], np.nan)\n",
    "df_aux['sum_1924_singleS_fullQ'] = np.where(df_aux['sumwage'] > 1924, df_aux['maxwage'], np.nan)\n",
    "df_aux['max_3848_singleS_fullQ'] = np.where(df_aux['maxwage'] > 3848, df_aux['maxwage'], np.nan)\n",
    "df_aux['sum_3848_singleS_fullQ'] = np.where(df_aux['sumwage'] > 3848, df_aux['maxwage'], np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can generate boxplots of the wages we found using the different definitions that we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16,6))\n",
    "df_aux[['max_0_singleS_fullQ','sum_0_singleS_fullQ','max_1924_singleS_fullQ',\n",
    "                   'sum_1924_singleS_fullQ','max_3848_singleS_fullQ','sum_3848_singleS_fullQ']].boxplot()\n",
    "ax.set_ylim(0,25000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see for example that the spread is smaller if we define a threshold and also the median is higher in such cases. Also, we see that the differences between 'sum' and 'max' are minor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_aux[['max_0_singleS_fullQ','sum_0_singleS_fullQ','max_1924_singleS_fullQ',\n",
    "                   'sum_1924_singleS_fullQ','max_3848_singleS_fullQ','sum_3848_singleS_fullQ']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the number of observations per variable, we also see differences. If we would define employment using the first listed definition, the employment rate for this cohort of students English would be much higher compared to if we would have used the last definition listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Sources of Error and Inference\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now you can ask yourself a few questions: \n",
    "\n",
    "Do you think these employment rates and median wages could be used for policy purposes to evaluate the Bachelor English in Ohio? Why/why not? \n",
    "\n",
    "What information are we missing that might make these results less usefull? \n",
    "Information we might be missing:\n",
    "- Employment of persons in other states than the ones we were able to investigate\n",
    "- Employment at federal government is not included in the dataset\n",
    "- People who are self-employed \n",
    "\n",
    "What do you think of the definitions that we made? How would you interpret the median wage values as we have no information whether the persons are full-time or part-time employed. Is setting a threshold a solution for this? \n",
    "\n",
    "How would the results be different for different education types and/or different cohorts? You can try this out by changing the first set of code that identifies the cohort.\n",
    "\n",
    "How would the results be different if we used a different definition for employment. So instead of 'full quarter employment', we for example used 'single quarter employment'? You can also try this yourself. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-ada",
   "language": "python",
   "name": "py3-ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
